{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08edb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloaders for the 4DeNoise project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed5b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import hyperspy.api as hs\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27dd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings the inference area i.e. the area that will be uses as input to the NN\n",
    "# 2 before, 2 after\n",
    "inference_H=1\n",
    "inference_W=5\n",
    "x_offset=2\n",
    "y_offset=0\n",
    "\"\"\"\n",
    "#For surrounding 8 instead\n",
    "inference_H=3\n",
    "inference_W=3\n",
    "x_offset=1\n",
    "y_offset=1\n",
    "\"\"\"\n",
    "#Coords of input pixels relative to output pixel. In [y,x] (numpy) order\n",
    "inputs_coords=[]\n",
    "for y in range(inference_H):\n",
    "    for x in range(inference_W):\n",
    "        coords=[x-x_offset,y-y_offset]\n",
    "        if coords[0]!=0 or coords[1]!=0: #i.e. coords is not [0,0]\n",
    "            inputs_coords.append(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c42cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom dataset object\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        #file_paths here is a list of paths refers to a list of paths to files that are used as sources of data\n",
    "        self.imgs=[]\n",
    "        for file_path in file_paths:\n",
    "            self.imgs.append(hs.load(file_path, reader=\"hspy\"))\n",
    "\n",
    "    #Height and width\n",
    "    def img_H(self,img_index):\n",
    "        return self.imgs[img_index].data.shape[2]\n",
    "\n",
    "    def img_W(self,img_index):\n",
    "        return self.imgs[img_index].data.shape[3]\n",
    "\n",
    "    def index_location(self, index): #FInds a location in i, y, x (i being the img_index) of pixel number index\n",
    "        if index>self.__len__():\n",
    "            raise ValueError(\"Index too high\")\n",
    "\n",
    "        running_total=0\n",
    "        for img_index in range(len(self.imgs)):\n",
    "            new_running_total=running_total+((self.img_H(img_index)+1-inference_H)*(self.img_W(img_index)+1-inference_W))\n",
    "            if index<new_running_total: #It's in this image\n",
    "                difference=index-running_total\n",
    "                x_pos=difference%self.img_W(img_index)\n",
    "                y_pos=difference//self.img_W(img_index)\n",
    "                return img_index, y_pos, x_pos\n",
    "            else:\n",
    "                running_total=new_running_total\n",
    "\n",
    "    def __len__(self):\n",
    "        running_total=0\n",
    "        for img_index in range(len(self.imgs)):\n",
    "            running_total+=(self.img_H(img_index)+1-inference_H)*(self.img_W(img_index)+1-inference_W)\n",
    "        return running_total\n",
    "    \n",
    "    #Function that returns input/output pair \n",
    "    def getitem(self, index):\n",
    "\n",
    "        img_index, y_pos, x_pos=self.index_location(index)\n",
    "        \n",
    "        item_input=torch.tensor(self.imgs[img_index].data[y_pos,x_pos],dtype = torch.float64)\n",
    "        item_output=[]\n",
    "        for coords in inputs_coords:\n",
    "            item_output.append(self.imgs[img_index].data[y_pos+coords[0],x_pos+coords[1]])\n",
    "        item_output=torch.tensor(item_output,dtype = torch.float64)\n",
    "        \n",
    "        return item_input,item_output\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.getitem(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b02d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m03855jw\\AppData\\Local\\hyperspy-bundle\\Lib\\site-packages\\hyperspy\\io.py:651: VisibleDeprecationWarning: Loading old file version. The binned attribute has been moved from metadata.Signal to axis.is_binned. Setting this attribute for all signal axes instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Change file location to that of noisy data. Right now, I am assuemd a hspy format. You can use a list of multiple 4D images\n",
    "testing_dataset=DataSet([r\"C:\\Users\\m03855jw\\Downloads\\4D-STEM_data_for_anthracene\\4D-STEM_data_for_anthracene\\Mg31872\\20221020_211713_data_binned2.hdf5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a8914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
