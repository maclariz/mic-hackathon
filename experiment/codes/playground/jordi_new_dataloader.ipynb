{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f176c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom DataSet\n",
    "\n",
    "'''\n",
    "This module contains all utilities needed to load training data and the live diffraction pattern for denoising into pytorch \n",
    "\n",
    "Functions will be added in due course\n",
    "\n",
    "All assumes that data is held in memory as numpy files currently\n",
    "\n",
    "If necessary, we could investigate modifying this to holding data as cupy arrays if there is a suitable GPU with enough memory to hold these\n",
    "'''\n",
    "\n",
    "#Importing libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#Custom dataset object\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Makes a Dataset object for torch given a path to a dataset in a hdf5 file\n",
    "\n",
    "    It implements Rx and Ry which are the largest pixel index along the vertical (Rx) and \n",
    "    horizontal (Ry) axes (which preserves the standard axis order of numpy, which is a \n",
    "    right-handed coordinate system, and uses the terminology of py4DSTEM).  Calling horizontal\n",
    "    x and vertical y when the vertical axis is index downwards flips the axis system to a \n",
    "    left-handed system and is best avoided (although that is the choice in hyperspy)\n",
    "\n",
    "    A range of selectors are available for selecting the pixels around the one of interest for \n",
    "    the video denoising\n",
    "\n",
    "    getitem uses the chosen selector in defining the pixels chosen for return of diffraction\n",
    "    patterns in surrounding pixels in item_input\n",
    "    \n",
    "    the original pixel diffraction pattern is returned in item_output\n",
    "    '''\n",
    "    def __init__(self, file_paths, samplershape='5l'):\n",
    "        '''\n",
    "        A deliberate choice is made to just select one file to map from, so self.imgs only has one item. I would recommend upgrading this software\n",
    "        so it can handle multiple images\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath: string\n",
    "            file path of the single 4D STEM data file to be loaded\n",
    "\n",
    "        samplershape: string\n",
    "            See self.selector().\n",
    "        '''\n",
    "        self.imgs=[]\n",
    "        file_path=file_paths[0]\n",
    "        f = h5py.File(file_path, 'r')\n",
    "        self.imgs.append(f['Experiments/__unnamed__/data/'])\n",
    "        self.samplershape=samplershape\n",
    "        \n",
    "        #Because of the sampler, we have to downsample, cannot train with all pixels of the image, we have to exclude some at the edges\n",
    "        if self.samplershape==\"5l\":\n",
    "            self.top_exclude=2\n",
    "            self.bottom_exclude=2\n",
    "            self.left_exclude=0\n",
    "            self.right_exclude=0\n",
    "            self.n=4\n",
    "        if self.samplershape==\"3d\":\n",
    "            self.top_exclude=1\n",
    "            self.bottom_exclude=1\n",
    "            self.left_exclude=1\n",
    "            self.right_exclude=1\n",
    "            self.n=4\n",
    "        if self.samplershape==\"3s\":\n",
    "            self.top_exclude=1\n",
    "            self.bottom_exclude=1\n",
    "            self.left_exclude=1\n",
    "            self.right_exclude=1\n",
    "            self.n=8\n",
    "        if self.samplershape==\"5d\":\n",
    "            self.top_exclude=2\n",
    "            self.bottom_exclude=2\n",
    "            self.left_exclude=2\n",
    "            self.right_exclude=2\n",
    "            self.n=12\n",
    "\n",
    "    #Height and width\n",
    "    def Rx(self):\n",
    "        '''\n",
    "        Size in real space in vertical direction\n",
    "        '''\n",
    "        return self.imgs[0].shape[0]\n",
    "\n",
    "    def Ry(self):\n",
    "        '''\n",
    "        Size in real space in horizontal direction\n",
    "        '''\n",
    "        return self.imgs[0].shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This is just the name of usubale pixels in the downsamples frame.\n",
    "        If this software is changed to multi-image, we will have to change this\n",
    "        \"\"\"\n",
    "        return (self.imgs[0].shape[0]-self.top_exclude-self.bottom_exclude)*(self.imgs[0].shape[1]-self.left_exclude-self.right_exclude)\n",
    "\n",
    "    #Note that this uses the sane person co-ordinate convention (x,y), while the rest of the program uses numpy convention (y,x), with weird results (e.g. the line for 5l is actually in the y-direction. We should probably fix this.)\n",
    "    def selector(self, Rx_pos, Ry_pos, samplershape='5l'):\n",
    "        '''\n",
    "        Makes a selection of suitable points for video averaging from a dataset being recorded, \n",
    "        and works with a few different shapes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: np.ndarray\n",
    "            a 4-dimensional STEM dataset, with axes in order Rx, Ry, Qx, Qy (same as py4DSTEM)\n",
    "        Rx: int\n",
    "            index along the Rx direction (vertical down)\n",
    "        Ry: int\n",
    "            index along the Ry direction\n",
    "        shape: str\n",
    "            A predefined str for the shape of area to extract the patch from for video denoising\n",
    "            Currently supported shapes:\n",
    "                5l: a line 5 long along the horizontal direction, skipping the centre: xxoxx\n",
    "                3d: a diamond 3 wide: oxo\n",
    "                                      xox\n",
    "                                      oxo\n",
    "                3s: a square 3 wide:  xxx\n",
    "                                      xox\n",
    "                                      xxx\n",
    "                5d: a diamond 5 wide: ooxoo\n",
    "                                      oxxxo\n",
    "                                      xxoxx\n",
    "                                      oxxxo\n",
    "                                      ooxoo\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DPs: np.ndarray\n",
    "            A 3D array of dimensions (n,Qx,Qy), n is the number of diffraction patterns returned for video denoising\n",
    "        \n",
    "        '''\n",
    "        assert samplershape in ['5l','3d','3s','5d'], 'Undefined Shape Code, please choose 5l, 3d, 3s or 5d'\n",
    "        if samplershape == '5l':\n",
    "            slicer = np.mgrid[0:1,-2:3]\n",
    "            keep = np.ones_like(slicer).astype('bool')[0]\n",
    "            keep[\n",
    "                [0],\n",
    "                [2]\n",
    "            ] = False\n",
    "            slicer = slicer[:,keep]\n",
    "        elif samplershape == '3d' or '3s':\n",
    "            slicer = np.mgrid[-1:2,-1:2]\n",
    "            keep = np.ones_like(slicer).astype('bool')[0]\n",
    "            if samplershape == '3d':\n",
    "                keep[\n",
    "                    [0,2,1,0,2],\n",
    "                    [0,0,1,2,2]\n",
    "                ] = False\n",
    "            elif samplershape == '3s':\n",
    "                keep[\n",
    "                    1,\n",
    "                    1\n",
    "                ] = False\n",
    "            slicer = slicer[:,keep]\n",
    "        elif samplershape == '5d':\n",
    "            slicer = np.mgrid[-2:3,-2:3]\n",
    "            keep = np.ones_like(slicer).astype('bool')[0]\n",
    "            keep[\n",
    "                [0,1,3,4,0,4,2,0,4,0,1,3,4],\n",
    "                [0,0,0,0,1,1,2,3,3,4,4,4,4]\n",
    "            ] = False\n",
    "            slicer = slicer[:,keep]\n",
    "        \n",
    "        # Shift the slicer to the chosen scan position\n",
    "        shifted_slicer = (slicer.T+np.array([Rx_pos,Ry_pos])).T\n",
    "        # Only keep selections that are within top and left boundaries\n",
    "        keepTL = np.where(np.logical_and(shifted_slicer[0]>=0,shifted_slicer[1]>=0))[0]\n",
    "        shifted_slicer_1 = shifted_slicer[:,keepTL]\n",
    "        # Only keep selections that are inside the bottom and right boundaries\n",
    "        keepBR = np.where(np.logical_and(shifted_slicer_1[0]<self.Rx(),shifted_slicer_1[1]<self.Ry()))[0]\n",
    "        coord_list = (shifted_slicer_1[:,keepBR]).T\n",
    "        \n",
    "        return coord_list\n",
    "\n",
    "    def getitem(self, index, samplershape='5l'):\n",
    "        '''\n",
    "        gets the real space positions to select from the input of index\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index: int\n",
    "            Index corresponding to a usuable pixel on the downsampled image, starting at lowest\n",
    "            x and y and increasing x first, then y.\n",
    "        samplershape: str\n",
    "            Described in selector (above)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        item_input:\n",
    "            input to ML model, which will be a tensor of shape (n,Qx,Qy), where Qx and Qy\n",
    "            are the sizes of the data in the diffraction directions vertically and horizontally.\n",
    "            n will depend on samplershape and on the position in the scan.\n",
    "        item_output:\n",
    "            currently just returns the diffraction pattern at the pixel at the index point\n",
    "            as tensor of shape (Qx,Qy)\n",
    "        '''\n",
    "        \n",
    "        Rx_pos=self.left_exclude+(index%(self.imgs[0].shape[1]-self.left_exclude-self.right_exclude))\n",
    "        Ry_pos=self.top_exclude+(index%(self.imgs[0].shape[1]-self.top_exclude-self.bottom_exclude))\n",
    "        print(\"x and y:\", Rx_pos, Ry_pos)\n",
    "        coord_list = self.selector(Rx_pos, Ry_pos, samplershape)\n",
    "        item_output=torch.tensor(self.imgs[0][Rx_pos, Ry_pos],dtype = torch.float64)\n",
    "        item_input=[]\n",
    "        for coords in coord_list:\n",
    "            item_input.append(self.imgs[0][coords[0],coords[1]])\n",
    "        item_input=torch.tensor(item_input,dtype = torch.float64)\n",
    "\n",
    "        if item_input.shape[0]!=self.n:\n",
    "            ValueError(\"Incorrect number of channels. This is probably because, somehow,\" \\\n",
    "            \"values of Rx_pos and Ry_pos have been chosen that are near the edge of the\" \\\n",
    "            \"image, so the samples is off the edge of the image and cannot sample fully.\")\n",
    "\n",
    "        return item_input, item_output\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.getitem(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4396f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change file location to that of noisy data. Right now, I am assuemd a hspy format. You can use a list of multiple 4D images\n",
    "testing_dataset=DataSet([r\"C:\\Users\\m03855jw\\Downloads\\4D-STEM_data_for_anthracene\\4D-STEM_data_for_anthracene\\Mg31872\\20221020_211713_data_binned2.hdf5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15f4c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x and y: 0 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 257, 257])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=testing_dataset.getitem(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d0919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}